from fastapi import FastAPI, HTTPException, Request, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import asyncio
import time
import os
import json
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
import threading
from contextlib import asynccontextmanager

# Import our enhanced modules
from config import config
from container import container
from cache import quantum_cache
from monitoring import (
    metrics_collector,
    metrics_middleware,
    get_metrics,
    get_health,
    REQUEST_COUNT,
    SIMULATION_DURATION,
    ACTIVE_WORKERS,
)
from rate_limiting import (
    limiter,
    quantum_rate_limit_middleware,
    rate_limit_exceeded_handler,
    limit_general_requests,
    limit_ibm_requests,
    limit_simulation_requests,
)
from models import (
    QuantumExecutionRequest,
    QuantumExecutionResult,
    IBMConnectRequest,
    IBMConnectResponse,
    IBMBackendsResponse,
    IBMExecuteRequest,
    IBMExecuteResponse,
    IBMJobStatusResponse,
    AIQuestionRequest,
    AIQuestionResponse,
    CacheStatsResponse,
    HealthResponse,
    QuantumMLFeatureMapRequest,
    QuantumMLKernelRequest,
    QuantumMLVQCTrainRequest,
    QuantumMLVQCPredictRequest,
    DatasetGenerateRequest,
    DatasetGenerateResponse,
    MedicalLoadRequest,
    MedicalAnalyzeRequest,
    ErrorResponse,
)

# Import legacy modules (keeping for compatibility)
from quantum_executor import execute_circuit_locally, validate_circuit_data
from quantum_api_types import BackendType, QuantumExecutionOptions
from quantum_api_bridge import QuantumAPI, execute_quantum_circuit_sync
from quantum_knowledge_base import ask_ai_question
from quantum_worker import QuantumWorker, QuantumWorkerPool, simulate_circuit_async
from ts_sim_port import (
    Circuit as TsCircuit,
    Gate as TsGate,
    simulate_circuit as simulate_circuit_ts,
)
from quantum_ml_primitives import (
    FeatureMap,
    ZFeatureMap,
    ZZFeatureMap,
    AmplitudeEncoding,
    QuantumKernel,
    FidelityQuantumKernel,
    ProjectedQuantumKernel,
    QNNLayer,
    VariationalLayer,
    DataEncodingLayer,
    MeasurementLayer,
    VariationalQuantumClassifier,
    VQCConfig,
    generate_classification_dataset,
    generate_regression_dataset,
    evaluate_classification,
    evaluate_regression,
    serialize_model,
    deserialize_model,
)
from quantum_data_preprocessing import (
    QuantumDataPreprocessor,
    DataSample,
    standardize_features,
    normalize_features,
    encode_for_quantum,
    reduce_dimensionality,
    create_train_validation_split,
    analyze_quantum_readiness,
)
import kagglehub
from medical_core import medical_core, download_csv_from_drive

# Load environment variables
from dotenv import load_dotenv

load_dotenv()

# IBM Quantum service
from ibm_service import ibm_service_instance

# Create FastAPI app with enhanced configuration
app = FastAPI(
    title="Quantum Backend API",
    version="2.0.0",
    description="Enhanced Quantum Computing Backend with Advanced Features",
    docs_url="/docs",
    redoc_url="/redoc",
)

# Import API versioning
from api_versioning import (
    version_middleware,
    versioned_router,
    create_versioned_router,
    APIVersion,
)
from routers import v1, v2

# Register versioned routers
versioned_router.register_version("v1", v1.v1_router, deprecated=True)
versioned_router.register_version("v2", v2.v2_router, deprecated=False)

# Include versioned routers
app.include_router(v1.v1_router)
app.include_router(v2.v2_router)


# Add versioning middleware
@app.middleware("http")
async def api_version_middleware(request: Request, call_next):
    return await version_middleware(request, call_next)


# Setup security middleware
from security import setup_security_middleware

setup_security_middleware(app)

# Analytics router removed
# from job_analytics import router as analytics_router
# app.include_router(analytics_router)

# ============================================================================
# Enhanced CORS Configuration
# ============================================================================
# Use regex to allow any local/network origin while supporting credentials
# app.add_middleware(
# CORSMiddleware,
# allow_origins=["*"],  # Allow all origins
# allow_credentials=False, # Credentials cannot be true with wildcards, and aren't used for JWT/cookies here
# allow_methods=["*"],
# allow_headers=["*"],
# )
origins = [
    "http://localhost:8080",  # frontend
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,  # or ["*"] for testing only
    allow_credentials=True,
    allow_methods=["*"],  # GET, POST, PUT, DELETE, OPTIONS
    allow_headers=["*"],  # Authorization, Content-Type, etc
)

# ============================================================================
# Enhanced Middleware Stack
# ============================================================================

# Rate limiting middleware
app.add_middleware(limiter, error_handler=rate_limit_exceeded_handler)


# Custom quantum rate limiting
@app.middleware("http")
async def enhanced_rate_limiting_middleware(request: Request, call_next):
    return await quantum_rate_limit_middleware(request, call_next)


# Metrics collection middleware
@app.middleware("http")
async def enhanced_metrics_middleware(request: Request, call_next):
    return await metrics_middleware(request, call_next)


# Security
security = HTTPBearer(auto_error=False)

# ============================================================================
# Enhanced Health and Monitoring Endpoints
# ============================================================================


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Enhanced health check with dependency verification"""
    return await get_health()


@app.get("/metrics")
async def prometheus_metrics():
    """Prometheus metrics endpoint"""
    return await get_metrics()


# Cache management endpoints
@app.get("/api/cache/stats", response_model=CacheStatsResponse)
async def get_cache_stats():
    """Get detailed cache statistics"""
    stats = await quantum_cache.get_stats()
    return CacheStatsResponse(success=True, cache=stats)


@app.delete("/api/cache/clear")
async def clear_cache():
    """Clear all cached data"""
    await quantum_cache.clear_all()
    container.logger.info("cache_cleared", source="api")
    return {"success": True, "message": "All caches cleared successfully"}


# ============================================================================
# Enhanced IBM Quantum Endpoints
# ============================================================================


@app.post("/api/ibm/connect", response_model=IBMConnectResponse)
@limit_ibm_requests()
async def connect_ibm(request: IBMConnectRequest):
    """Connect to IBM Quantum with enhanced validation and logging"""
    start_time = time.time()

    try:
        container.logger.info(
            "ibm_connection_attempt",
            token_prefix=request.token[:10] if request.token else "none",
        )

        # Print to console for debugging
        print(
            f"[IBM] ğŸ” Connecting with token: {request.token[:10]}..."
            if request.token
            else "[IBM] âŒ No token provided"
        )
        print(f"[IBM] ğŸ“¡ Validating token with IBM Quantum...")

        result = await ibm_service_instance.validate_token(request.token)

        duration = time.time() - start_time
        await metrics_collector.record_ibm_api_call(
            "connect", result.get("success", False)
        )

        if result.get("success"):
            hub = result.get("hub", "unknown")
            channel = result.get("channel", "unknown")
            print(f"[IBM] âœ… Connection successful! Hub: {hub}, Channel: {channel}")
            container.logger.info(
                "ibm_connection_success", hub=hub, channel=channel, duration=duration
            )
        else:
            error = result.get("error", "Unknown error")
            print(f"[IBM] âŒ Connection failed: {error}")
            container.logger.warning(
                "ibm_connection_failed", error=error, duration=duration
            )

        return IBMConnectResponse(**result)

    except Exception as e:
        duration = time.time() - start_time
        await metrics_collector.record_ibm_api_call("connect", False)
        error_msg = str(e)
        print(f"[IBM] âŒ Connection error: {error_msg}")
        container.logger.error(
            "ibm_connection_error", error=error_msg, duration=duration
        )
        raise IBMQuantumError(
            f"IBM Quantum connection failed: {error_msg}",
            details={"duration": duration},
        )


@app.get("/api/ibm/backends", response_model=IBMBackendsResponse)
@limit_general_requests()
async def get_ibm_backends(request: Request, token: str):
    """Get available IBM Quantum backends with caching and logging"""
    try:
        print(f"[IBM] ğŸ” Fetching backends for token: {token[:10]}...")

        # Check cache first
        cache_key = f"ibm_backends:{token[:16]}"
        cached_result = await quantum_cache.backend.get(cache_key)

        if cached_result:
            await metrics_collector.record_cache_hit("ibm_backends")
            container.logger.debug("ibm_backends_cache_hit")
            print(
                f"[IBM] âœ… Backends retrieved from cache ({len(cached_result.get('backends', []))} backends)"
            )
            return IBMBackendsResponse(**cached_result)

        await metrics_collector.record_cache_miss("ibm_backends")

        result = await ibm_service_instance.get_backends(token)

        # Cache for 5 minutes
        if result.get("success"):
            backend_count = len(result.get("backends", []))
            print(f"[IBM] âœ… Found {backend_count} backends")
            await quantum_cache.backend.set(cache_key, result, ttl=300)
        else:
            print(
                f"[IBM] âŒ Failed to get backends: {result.get('error', 'Unknown error')}"
            )

        return IBMBackendsResponse(**result)

    except Exception as e:
        error_msg = str(e)
        print(f"[IBM] âŒ Backends error: {error_msg}")
        container.logger.error("ibm_backends_error", error=error_msg)
        raise IBMQuantumError(f"Failed to get IBM backends: {error_msg}")


@app.post("/api/ibm/execute", response_model=IBMExecuteResponse)
@limit_ibm_requests()
async def execute_ibm(request: IBMExecuteRequest):
    """Execute circuit on IBM Quantum with enhanced error handling and logging"""
    start_time = time.time()

    try:
        print(f"[IBM] ğŸš€ Submitting job to backend: {request.backend}")
        print(
            f"[IBM] ğŸ“Š Circuit: {request.circuit.numQubits} qubits, {len(request.circuit.gates)} gates, {request.shots} shots"
        )

        container.logger.info(
            "ibm_execution_started",
            backend=request.backend,
            shots=request.shots,
            circuit_size=len(request.circuit.gates),
        )

        result = await ibm_service_instance.submit_job(
            request.token, request.backend, request.circuit.dict(), request.shots
        )

        duration = time.time() - start_time
        await metrics_collector.record_ibm_api_call(
            "execute", result.get("success", False)
        )

        if result.get("success"):
            job_id = result.get("jobId")
            status = result.get("status")
            print(f"[IBM] âœ… Job submitted successfully!")
            print(f"[IBM] ğŸ“‹ Job ID: {job_id}")
            print(f"[IBM] ğŸ“Š Status: {status}")
            container.logger.info(
                "ibm_job_submitted", job_id=job_id, status=status, duration=duration
            )
        else:
            error = result.get("error", "Unknown error")
            print(f"[IBM] âŒ Job submission failed: {error}")
            container.logger.warning("ibm_job_failed", error=error, duration=duration)

        return IBMExecuteResponse(**result)

    except Exception as e:
        duration = time.time() - start_time
        await metrics_collector.record_ibm_api_call("execute", False)
        error_msg = str(e)
        print(f"[IBM] âŒ Execution error: {error_msg}")
        container.logger.error(
            "ibm_execution_error", error=error_msg, duration=duration
        )
        raise IBMQuantumError(
            f"IBM Quantum execution failed: {error_msg}", details={"duration": duration}
        )


@app.get("/api/ibm/job/{job_id}", response_model=IBMJobStatusResponse)
@limit_general_requests()
async def get_ibm_job(request: Request, job_id: str, token: str):
    """Get IBM Quantum job status with caching and logging"""
    try:
        print(f"[IBM] ğŸ” Checking job status: {job_id}")

        # Check cache first (short TTL for job status)
        cache_key = f"ibm_job:{job_id}"
        cached_result = await quantum_cache.backend.get(cache_key)

        if cached_result:
            await metrics_collector.record_cache_hit("ibm_job_status")
            status = cached_result.get("status", "unknown")
            print(f"[IBM] ğŸ“‹ Job status (cached): {status}")
            return IBMJobStatusResponse(**cached_result)

        await metrics_collector.record_cache_miss("ibm_job_status")

        result = await ibm_service_instance.get_job_result(token, job_id)

        # Cache for 30 seconds (job status changes frequently)
        if result.get("success"):
            status = result.get("status", "unknown")
            print(f"[IBM] ğŸ“‹ Job status: {status}")

            if status == "DONE":
                results = result.get("results", {})
                print(
                    f"[IBM] âœ… Job completed! Results: {len(results)} measurement outcomes"
                )
                if results:
                    # Print first few results
                    sample_results = dict(list(results.items())[:5])
                    print(f"[IBM] ğŸ“Š Sample results: {sample_results}")

            await quantum_cache.backend.set(cache_key, result, ttl=30)

        await metrics_collector.record_ibm_api_call(
            "job_status", result.get("success", False)
        )

        return IBMJobStatusResponse(**result)

    except Exception as e:
        error_msg = str(e)
        print(f"[IBM] âŒ Job status error: {error_msg}")
        container.logger.error("ibm_job_status_error", job_id=job_id, error=error_msg)
        raise IBMQuantumError(
            f"Failed to get job status: {error_msg}", details={"job_id": job_id}
        )


# Keep existing endpoints for backward compat

# Authentication error (REMOVED)


# ============================================================================
# Enhanced Circuit Execution Endpoint
# ============================================================================


@app.post("/api/quantum/execute", response_model=QuantumExecutionResult)
@limit_simulation_requests()
async def execute_circuit(request: QuantumExecutionRequest):
    """Execute quantum circuit with enhanced caching, metrics, and validation"""
    start_time = time.time()

    try:
        container.logger.info(
            "circuit_execution_started",
            backend=request.backend,
            num_qubits=request.circuit.numQubits,
            num_gates=len(request.circuit.gates),
            shots=request.shots,
        )

        # Check cache for simulation results
        cached_result = await quantum_cache.get_simulation_result(
            request.circuit.dict(), request.backend.value
        )

        if cached_result:
            await metrics_collector.record_cache_hit("simulation")
            container.logger.info("circuit_cache_hit", backend=request.backend.value)
            return QuantumExecutionResult(**cached_result)

        await metrics_collector.record_cache_miss("simulation")

        # Map backend name to BackendType
        backend_mapping = {
            "local": BackendType.LOCAL,
            "aer_simulator": BackendType.AER_SIMULATOR,
            "custom_simulator": BackendType.CUSTOM_SIMULATOR,
            "wasm": BackendType.WASM,
        }
        backend = backend_mapping.get(request.backend.value, BackendType.LOCAL)

        # Create execution options
        options = QuantumExecutionOptions(
            backend=backend,
            token=request.token,
            shots=request.shots,
            initial_state=request.initialState or "ket0",
            custom_state=request.customState,
            optimization_level=1,
            enable_transpilation=True,
            backend_name=request.backend.value,
        )

        # Execute using unified API
        result = await QuantumAPI().execute_quantum_circuit(
            request.circuit.dict(), options
        )

        # Record metrics
        duration = time.time() - start_time
        await metrics_collector.record_simulation(
            request.backend.value, result.success, duration
        )

        # Format response
        response_data = {
            "success": result.success,
            "method": result.method,
            "backend": result.backend,
            "executionTime": result.execution_time,
        }

        if result.qubit_results:
            response_data["qubitResults"] = result.qubit_results
        if result.job_id:
            response_data["jobId"] = result.job_id
        if result.status:
            response_data["status"] = result.status
        if result.message:
            response_data["message"] = result.message
        if result.error:
            response_data["error"] = result.error

        # Cache successful results
        if result.success and not result.job_id:  # Don't cache async jobs
            await quantum_cache.set_simulation_result(
                request.circuit.dict(), request.backend.value, response_data
            )

        container.logger.info(
            "circuit_execution_completed",
            success=result.success,
            duration=duration,
            backend=request.backend.value,
        )

        return QuantumExecutionResult(**response_data)

    except Exception as e:
        duration = time.time() - start_time
        await metrics_collector.record_simulation(
            request.backend.value, False, duration
        )

        container.logger.error(
            "circuit_execution_failed",
            error=str(e),
            backend=request.backend.value,
            duration=duration,
        )

        raise CircuitExecutionError(
            f"Failed to execute quantum circuit: {str(e)}",
            details={
                "backend": request.backend.value,
                "duration": duration,
                "num_qubits": request.circuit.numQubits,
                "num_gates": len(request.circuit.gates),
            },
        )


# ---------------------------------------------------------------------------
# TS-port real-valued simulator (density-matrix) wrapper
# ---------------------------------------------------------------------------
@app.post("/api/quantum/execute/ts-port")
async def execute_circuit_ts_port(data: Dict[str, Any]):
    """
    Execute using the Python port of the TS core (ts_sim_port.py).
    Accepts: { circuit: { numQubits, gates:[{name, qubits, parameters?}] }, initialState?: string }
    """
    try:
        circuit_data = data.get("circuit")
        initial_state = data.get("initialState")
        if (
            not circuit_data
            or "numQubits" not in circuit_data
            or "gates" not in circuit_data
        ):
            raise HTTPException(status_code=400, detail="Invalid circuit payload")

        gates = [
            TsGate(
                name=g.get("name"),
                qubits=g.get("qubits", []),
                parameters=g.get("parameters"),
            )
            for g in circuit_data.get("gates", [])
        ]
        circuit = TsCircuit(numQubits=circuit_data["numQubits"], gates=gates)

        result = simulate_circuit_ts(circuit, initial_state)
        return {
            "success": True,
            "backend": "ts-port",
            "result": {
                "statevector": result.get("statevector"),
                "probabilities": result.get("probabilities"),
                "densityMatrix": result.get("densityMatrix"),
                "reducedStates": result.get("reducedStates"),
            },
        }
    except (HTTPException, QuantumAPIError):
        raise
    except Exception as e:
        container.logger.error("ts_port_execution_error", error=str(e))
        raise CircuitExecutionError(
            f"TS-port execution failed: {str(e)}", details={"backend": "ts-port"}
        )


# ---------------------------------------------------------------------------
# Complex statevector simulator wrapper (qiskit_simulator.py)
# ---------------------------------------------------------------------------
@app.post("/api/quantum/execute/statevector")
async def execute_circuit_statevector(data: Dict[str, Any]):
    """
    Execute using backend/qiskit_simulator.py (Qiskit-based simulation).
    Accepts: { circuit: { numQubits, gates:[{name, qubits, parameters?}] }, initialState: 'ket0'|..., customState? }
    """
    try:
        from qiskit_simulator import execute_circuit as execute_statevector

        result = execute_statevector(
            {
                "circuit": data.get("circuit"),
                "initialState": data.get("initialState", "ket0"),
                "customState": data.get("customState"),
            }
        )
        if not result.get("success"):
            raise HTTPException(
                status_code=500,
                detail=result.get("error", "Statevector execution failed"),
            )
        return {
            "success": True,
            "backend": "statevector",
            "result": result,
        }
    except (HTTPException, QuantumAPIError):
        raise
    except Exception as e:
        container.logger.error("statevector_execution_error", error=str(e))
        raise CircuitExecutionError(
            f"Statevector execution failed: {str(e)}",
            details={"backend": "statevector"},
        )


# Get available backends
@app.get("/api/quantum/backends")
async def get_backends():
    try:
        # Return only local backends
        default_backends = [
            {
                "id": "local",
                "name": "Local Simulator",
                "status": "available",
                "qubits": 24,
                "type": "simulator",
            },
            {
                "id": "custom_simulator",
                "name": "Custom Simulator",
                "status": "available",
                "qubits": 20,
                "type": "simulator",
            },
            {
                "id": "simulator_statevector",
                "name": "Statevector Simulator",
                "status": "available",
                "qubits": 24,
                "type": "simulator",
            },
            {
                "id": "simulator_mps",
                "name": "Matrix Product State Simulator",
                "status": "available",
                "qubits": 100,
                "type": "simulator",
            },
        ]
        return {"success": True, "backends": default_backends}

    except Exception as e:
        container.logger.error("backend_listing_error", error=str(e))
        return {"success": True, "backends": []}


# Job management endpoints (REMOVED)


# ============================================================================
# Enhanced AI Assistant Endpoint
# ============================================================================


@app.post("/api/ai/ask", response_model=AIQuestionResponse)
@limit_general_requests()
async def ask_ai(request: AIQuestionRequest):
    """Get AI assistance with caching and enhanced error handling"""
    start_time = time.time()

    try:
        container.logger.info(
            "ai_question_received", question_length=len(request.question)
        )

        # Check cache first
        cached_answer = await quantum_cache.get_ai_response(request.question)
        if cached_answer:
            await metrics_collector.record_cache_hit("ai_responses")
            container.logger.info("ai_cache_hit")
            return AIQuestionResponse(
                success=True,
                question=request.question,
                answer=cached_answer,
                timestamp=datetime.utcnow().isoformat(),
            )

        await metrics_collector.record_cache_miss("ai_responses")

        # Get AI response
        answer = await ask_ai_question(request.question)

        # Cache the response
        await quantum_cache.set_ai_response(request.question, answer)

        duration = time.time() - start_time

        container.logger.info(
            "ai_question_answered", duration=duration, answer_length=len(answer)
        )

        return AIQuestionResponse(
            success=True,
            question=request.question,
            answer=answer,
            timestamp=datetime.utcnow().isoformat(),
        )

    except Exception as e:
        duration = time.time() - start_time
        container.logger.error(
            "ai_question_failed",
            error=str(e),
            duration=duration,
            question_length=len(request.question),
        )

        raise QuantumAPIError(
            "Failed to get AI response" if not config.debug else str(e),
            status_code=500,
            error_code="AI_SERVICE_ERROR",
            details={"question_length": len(request.question), "duration": duration},
        )


# Download Dataset Endpoint
@app.post("/api/download-dataset")
async def download_dataset():
    try:
        print("Initiating dataset download...")
        path = kagglehub.dataset_download("masoudnickparvar/brain-tumor-mri-dataset")
        return {
            "success": True,
            "path": path,
            "message": "Dataset downloaded successfully.",
        }
    except Exception as e:
        container.logger.error("dataset_download_error", error=str(e))
        raise QuantumAPIError(
            f"Dataset download failed: {str(e)}",
            status_code=500,
            error_code="DATASET_ERROR",
        )


# ============================================================================
# QUANTUM MACHINE LEARNING ENDPOINTS
# ============================================================================


# Feature Map Operations
@app.post("/api/quantum-ml/feature-maps")
async def create_feature_map(data: Dict[str, Any]):
    """Create and apply a quantum feature map"""
    try:
        map_type = data.get("type", "z")
        num_qubits = data.get("numQubits", 2)
        input_data = data.get("data", [])

        # Create feature map
        if map_type.lower() == "z":
            feature_map = ZFeatureMap(num_qubits)
        elif map_type.lower() == "zz":
            feature_map = ZZFeatureMap(num_qubits)
        elif map_type.lower() == "amplitude":
            feature_map = AmplitudeEncoding(num_qubits)
        else:
            raise HTTPException(
                status_code=400, detail=f"Unsupported feature map type: {map_type}"
            )

        # Encode data
        circuit = feature_map.encode(input_data)

        return {
            "success": True,
            "featureMap": {
                "name": feature_map.name,
                "description": feature_map.description,
                "numQubits": num_qubits,
            },
            "circuit": {
                "numQubits": circuit.num_qubits,
                "gates": [
                    {"name": g.name, "qubits": g.qubits, "parameters": g.parameters}
                    for g in circuit.gates
                ],
            },
        }

    except Exception as e:
        container.logger.error("feature_map_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to create feature map: {str(e)}",
            status_code=500,
            error_code="ML_FEATURE_MAP_ERROR",
        )


# Quantum Kernel Operations
@app.post("/api/quantum-ml/kernels")
async def compute_quantum_kernel(data: Dict[str, Any]):
    """Compute quantum kernel between data points"""
    try:
        kernel_type = data.get("type", "fidelity")
        feature_map_type = data.get("featureMap", "z")
        x1 = data.get("x1", [])
        x2 = data.get("x2", [])

        # Create feature map
        num_qubits = max(len(x1), len(x2), 2)
        if feature_map_type.lower() == "z":
            feature_map = ZFeatureMap(num_qubits)
        elif feature_map_type.lower() == "zz":
            feature_map = ZZFeatureMap(num_qubits)
        else:
            feature_map = ZFeatureMap(num_qubits)

        # Create kernel
        if kernel_type.lower() == "fidelity":
            kernel = FidelityQuantumKernel()
        elif kernel_type.lower() == "projected":
            kernel = ProjectedQuantumKernel()
        else:
            kernel = FidelityQuantumKernel()

        # Compute kernel
        kernel_value = kernel.compute_kernel(x1, x2, feature_map)

        return {
            "success": True,
            "kernel": {
                "type": kernel.name,
                "value": kernel_value,
                "featureMap": feature_map.name,
            },
        }

    except Exception as e:
        container.logger.error("quantum_kernel_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to compute quantum kernel: {str(e)}",
            status_code=500,
            error_code="ML_KERNEL_ERROR",
        )


# Variational Quantum Circuit Operations
@app.post("/api/quantum-ml/variational-circuits")
async def create_variational_circuit(data: Dict[str, Any]):
    """Create a variational quantum circuit"""
    try:
        num_qubits = data.get("numQubits", 2)
        num_layers = data.get("numLayers", 1)
        ansatz_type = data.get("ansatzType", "hardware_efficient")
        parameters = data.get("parameters", [])

        # Create variational layer
        variational_layer = VariationalLayer(
            num_qubits=num_qubits, num_layers=num_layers, ansatz_type=ansatz_type
        )

        # Build circuit
        circuit = variational_layer.build_circuit(parameters)

        return {
            "success": True,
            "circuit": {
                "numQubits": circuit.num_qubits,
                "gates": [
                    {"name": g.name, "qubits": g.qubits, "parameters": g.parameters}
                    for g in circuit.gates
                ],
                "numParameters": variational_layer.num_parameters,
            },
            "layer": {
                "name": variational_layer.name,
                "description": variational_layer.description,
                "numParameters": variational_layer.num_parameters,
            },
        }

    except Exception as e:
        container.logger.error("variational_circuit_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to create variational circuit: {str(e)}",
            status_code=500,
            error_code="ML_VARIATIONAL_ERROR",
        )


# Variational Quantum Classifier
@app.post("/api/quantum-ml/vqc/train")
async def train_vqc(data: Dict[str, Any]):
    """Train a Variational Quantum Classifier"""
    try:
        # Extract configuration
        feature_map_type = data.get("featureMap", "z")
        num_qubits = data.get("numQubits", 2)
        variational_layers = data.get("variationalLayers", 1)
        training_data = data.get("trainingData", [])
        labels = data.get("labels", [])
        max_iterations = data.get("maxIterations", 100)

        # Create feature map
        if feature_map_type.lower() == "z":
            feature_map = ZFeatureMap(num_qubits)
        elif feature_map_type.lower() == "zz":
            feature_map = ZZFeatureMap(num_qubits)
        else:
            feature_map = ZFeatureMap(num_qubits)

        # Create variational layer
        variational_layer = VariationalLayer(num_qubits, variational_layers)

        # Create measurement layer
        measurement_layer = MeasurementLayer(num_qubits)

        # Create VQC config
        config = VQCConfig(
            feature_map=feature_map,
            variational_layer=variational_layer,
            measurement_layer=measurement_layer,
            max_iterations=max_iterations,
        )

        # Create and train VQC
        vqc = VariationalQuantumClassifier(config)

        # Convert training data to expected format
        train_samples = [(x, y) for x, y in zip(training_data, labels)]

        # Train the model
        training_result = vqc.train(train_samples, labels, max_iterations)

        return {
            "success": True,
            "model": {
                "type": "VQC",
                "featureMap": feature_map.name,
                "numQubits": num_qubits,
                "numParameters": variational_layer.num_parameters,
            },
            "training": training_result,
            "parameters": vqc.parameters,
        }

    except Exception as e:
        container.logger.error("vqc_training_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to train VQC: {str(e)}",
            status_code=500,
            error_code="ML_VQC_TRAINING_ERROR",
        )


@app.post("/api/quantum-ml/vqc/predict")
async def predict_vqc(data: Dict[str, Any]):
    """Make predictions with a trained VQC"""
    try:
        parameters = data.get("parameters", [])
        feature_map_type = data.get("featureMap", "z")
        num_qubits = data.get("numQubits", 2)
        input_data = data.get("inputData", [])

        # Recreate model configuration
        if feature_map_type.lower() == "z":
            feature_map = ZFeatureMap(num_qubits)
        else:
            feature_map = ZFeatureMap(num_qubits)

        variational_layer = VariationalLayer(num_qubits)
        measurement_layer = MeasurementLayer(num_qubits)

        config = VQCConfig(
            feature_map=feature_map,
            variational_layer=variational_layer,
            measurement_layer=measurement_layer,
        )

        # Create model and set parameters
        vqc = VariationalQuantumClassifier(config)
        vqc.parameters = parameters

        # Make prediction
        prediction = vqc.predict(input_data)

        return {"success": True, "prediction": prediction}

    except Exception as e:
        container.logger.error("vqc_prediction_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to make VQC prediction: {str(e)}",
            status_code=500,
            error_code="ML_VQC_PREDICTION_ERROR",
        )


# ============================================================================
# ASYNCHRONOUS QUANTUM EXECUTION ENDPOINTS
# ============================================================================


# Asynchronous Circuit Execution
@app.post("/api/quantum/async/execute")
async def execute_circuit_async(data: Dict[str, Any]):
    """Execute quantum circuit asynchronously using worker"""
    try:
        circuit = data.get("circuit")
        initial_state = data.get("initialState", "ket0")
        task_id = data.get("taskId", f"task_{int(time.time() * 1000)}")

        if not circuit:
            raise HTTPException(status_code=400, detail="Circuit is required")

        # Create worker and execute asynchronously
        async with QuantumWorker() as worker:
            message = {
                "type": "simulate",
                "id": task_id,
                "data": {"circuit": circuit, "initialState": initial_state},
            }

            # Execute asynchronously
            response = await worker.execute(message)

            if response.type == "error":
                raise HTTPException(status_code=500, detail=response.error)

            return {
                "success": True,
                "taskId": task_id,
                "result": response.data,
                "status": "completed",
            }

    except (HTTPException, QuantumAPIError):
        raise
    except Exception as e:
        container.logger.error("async_execution_error", error=str(e))
        raise WorkerPoolError(f"Failed to execute circuit asynchronously: {str(e)}")


# Reduced states endpoint
@app.post("/api/reduced")
async def compute_reduced(data: Dict[str, Any]):
    """
    Compute reduced density matrices for the given code.
    Accepts: { code: string }
    Returns: { circuit: object, reducedStates: array }
    """
    try:
        code = data.get("code", "")
        if not code:
            raise HTTPException(status_code=400, detail="Code is required")

        # Parse the code into a circuit object
        from quantum_code_parser import parse_quantum_code
        from quantum_simulation import simulate_circuit as simulate_circuit_py

        circuit_obj = parse_quantum_code(code)

        # Simulate locally (Python density matrix simulator)
        result = simulate_circuit_py(circuit_obj)

        # Serialize for frontend
        reduced_states = []
        if result.reducedStates:
            reduced_states = [
                {
                    "matrix": state.matrix,
                    "blochVector": state.blochVector,
                    "purity": state.purity,
                    "entanglement": state.entanglement,
                    "superposition": state.superposition,
                }
                for state in result.reducedStates
            ]

        # Convert Simulation circuit to frontend format
        frontend_circuit = {
            "numQubits": circuit_obj.num_qubits,
            "gates": [
                {"name": g.name, "qubits": g.qubits, "parameters": g.parameters}
                for g in circuit_obj.gates
            ],
        }

        return {
            "success": True,
            "circuit": frontend_circuit,
            "reducedStates": reduced_states,
        }

    except Exception as e:
        container.logger.error("reduced_state_error", error=str(e))
        raise CircuitExecutionError(f"Failed to compute reduced states: {str(e)}")


# Worker Pool Status
@app.get("/api/quantum/workers/status")
async def get_worker_status():
    """Get comprehensive status of quantum worker pool"""
    try:
        from quantum_worker import QuantumWorkerPool
        from container import container

        # Get worker pool instance
        pool_instance = container.worker_pool()

        # Get pool status
        pool_status = (
            pool_instance.get_pool_status()
            if hasattr(pool_instance, "get_pool_status")
            else {}
        )

        return {
            "success": True,
            "pool": pool_status,
            "workers": {
                "active": pool_status.get("active_workers", 0),
                "total": pool_status.get("num_workers", 0),
                "healthy": pool_status.get("active_workers", 0),
            },
            "queue": {
                "pending": pool_status.get("queue_size", 0),
                "processing": sum(pool_status.get("worker_load", {}).values()),
            },
            "statistics": {
                "tasks_completed": pool_status.get("total_tasks_completed", 0),
                "tasks_failed": pool_status.get("total_tasks_failed", 0),
                "success_rate": (
                    pool_status.get("total_tasks_completed", 0)
                    / max(
                        pool_status.get("total_tasks_completed", 0)
                        + pool_status.get("total_tasks_failed", 0),
                        1,
                    )
                    * 100
                ),
            },
        }

    except Exception as e:
        container.logger.error("worker_status_error", error=str(e))
        raise WorkerPoolError(f"Failed to get worker status: {str(e)}")


# ============================================================================
# DATA PREPROCESSING ENDPOINTS
# ============================================================================


# Data Preprocessing
@app.post("/api/quantum-ml/preprocessing")
async def preprocess_data(data: Dict[str, Any]):
    """Apply quantum data preprocessing"""
    try:
        raw_data = data.get("data", [])
        config = data.get("config", {})

        # Convert to DataSample format
        samples = [
            DataSample(
                features=point.get("features", []),
                label=point.get("label"),
                target=point.get("target"),
            )
            for point in raw_data
        ]

        # Create preprocessor
        preprocessor = QuantumDataPreprocessor(config)

        # Fit and transform
        processed_samples = preprocessor.fit_transform(samples)

        # Convert back to dict format
        processed_data = [
            {
                "features": sample.features,
                "label": sample.label,
                "target": sample.target,
                "metadata": sample.metadata,
            }
            for sample in processed_samples
        ]

        return {
            "success": True,
            "processedData": processed_data,
            "statistics": preprocessor.get_statistics(),
            "config": preprocessor.export_config(),
        }

    except Exception as e:
        container.logger.error("data_preprocessing_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to preprocess data: {str(e)}",
            status_code=500,
            error_code="ML_PREPROCESSING_ERROR",
        )


# Generate Synthetic Datasets
@app.post("/api/quantum-ml/datasets/generate")
async def generate_dataset(data: Dict[str, Any]):
    """Generate synthetic quantum ML datasets"""
    try:
        dataset_type = data.get("type", "classification")
        subtype = data.get("subtype", "circles")
        num_samples = data.get("numSamples", 100)

        if dataset_type == "classification":
            features, labels = generate_classification_dataset(subtype, num_samples)
        elif dataset_type == "regression":
            features, labels = generate_regression_dataset(subtype, num_samples)
        else:
            raise HTTPException(
                status_code=400, detail=f"Unsupported dataset type: {dataset_type}"
            )

        # Convert to expected format
        dataset = [
            {
                "features": feat,
                "label": (
                    int(label)
                    if isinstance(label, (int, float))
                    and dataset_type == "classification"
                    else label
                ),
                "target": label if dataset_type == "regression" else None,
            }
            for feat, label in zip(features, labels)
        ]

        return {
            "success": True,
            "dataset": dataset,
            "type": dataset_type,
            "subtype": subtype,
            "numSamples": num_samples,
        }

    except (HTTPException, QuantumAPIError):
        raise
    except Exception as e:
        container.logger.error("dataset_generation_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to generate dataset: {str(e)}",
            status_code=500,
            error_code="ML_DATASET_ERROR",
        )


# Analyze Quantum Readiness
@app.post("/api/quantum-ml/analysis/quantum-readiness")
async def analyze_quantum_readiness_endpoint(data: Dict[str, Any]):
    """Analyze data for quantum ML compatibility"""
    try:
        raw_data = data.get("data", [])

        # Convert to DataSample format
        samples = [
            DataSample(features=point.get("features", []), label=point.get("label"))
            for point in raw_data
        ]

        # Analyze quantum readiness
        analysis = analyze_quantum_readiness(samples)

        return {"success": True, "analysis": analysis}

    except Exception as e:
        container.logger.error("quantum_readiness_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to analyze quantum readiness: {str(e)}",
            status_code=500,
            error_code="ML_ANALYSIS_ERROR",
        )


# Model Evaluation
@app.post("/api/quantum-ml/evaluation")
async def evaluate_model(data: Dict[str, Any]):
    """Evaluate quantum ML model performance"""
    try:
        predictions = data.get("predictions", [])
        true_labels = data.get("trueLabels", [])
        targets = data.get("targets", [])
        evaluation_type = data.get("type", "classification")

        if evaluation_type == "classification":
            metrics = evaluate_classification(predictions, true_labels)
        elif evaluation_type == "regression":
            metrics = evaluate_regression(predictions, targets)
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported evaluation type: {evaluation_type}",
            )

        return {
            "success": True,
            "metrics": {
                "accuracy": metrics.accuracy,
                "precision": metrics.precision,
                "recall": metrics.recall,
                "f1Score": metrics.f1_score,
                "mse": metrics.mse,
                "mae": metrics.mae,
            },
        }

    except (HTTPException, QuantumAPIError):
        raise
    except Exception as e:
        container.logger.error("model_evaluation_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to evaluate model: {str(e)}",
            status_code=500,
            error_code="ML_EVALUATION_ERROR",
        )


# Helper functions
async def get_backend_info(token: str, backend_id: str) -> Dict[str, Any]:
    """Get backend information from IBM Quantum"""
    try:
        import aiohttp

        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"https://api.quantum.ibm.com/runtime/backends/{backend_id}",
                headers={
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                },
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status >= 400:
                    raise Exception(f"Backend info request failed: {response.status}")

                backend = await response.json()
                return {
                    "id": backend_id,
                    "name": backend.get("name", backend_id),
                    "status": backend.get("status", "available"),
                    "qubits": backend.get("n_qubits", backend.get("num_qubits", 0)),
                    "type": "simulator" if backend.get("simulator") else "hardware",
                }
    except Exception as e:
        print(f"Backend info error: {e}")

        # Return default info for common backends
        default_backends = {
            "ibmq_qasm_simulator": {
                "name": "IBM QASM Simulator",
                "qubits": 32,
                "type": "simulator",
            },
            "simulator_statevector": {
                "name": "Statevector Simulator",
                "qubits": 24,
                "type": "simulator",
            },
            "simulator_mps": {
                "name": "Matrix Product State Simulator",
                "qubits": 100,
                "type": "simulator",
            },
            "ibmq_manila": {"name": "IBM Manila", "qubits": 5, "type": "hardware"},
            "ibmq_lima": {"name": "IBM Lima", "qubits": 5, "type": "hardware"},
            "ibmq_belem": {"name": "IBM Belem", "qubits": 5, "type": "hardware"},
            "ibmq_quito": {"name": "IBM Quito", "qubits": 5, "type": "hardware"},
            "ibm_brisbane": {"name": "IBM Brisbane", "qubits": 127, "type": "hardware"},
            "ibm_sherbrooke": {
                "name": "IBM Sherbrooke",
                "qubits": 127,
                "type": "hardware",
            },
        }

        return {
            "id": backend_id,
            "name": default_backends.get(backend_id, {}).get("name", backend_id),
            "status": "available",
            "qubits": default_backends.get(backend_id, {}).get("qubits", 0),
            "type": default_backends.get(backend_id, {}).get("type", "simulator"),
        }


async def get_available_backends(
    token: Optional[str] = None,
) -> tuple[List[Dict[str, Any]], bool]:
    """Get available backends from IBM Quantum"""
    try:
        effective_token = token if token is not None else os.getenv("IBM_QUANTUM_TOKEN")

        import aiohttp

        async with aiohttp.ClientSession() as session:
            async with session.get(
                "https://api.quantum.ibm.com/runtime/backends",
                headers={
                    "Authorization": f"Bearer {effective_token}",
                    "Content-Type": "application/json",
                },
                timeout=aiohttp.ClientTimeout(total=5),
            ) as response:
                if response.status >= 400:
                    raise Exception(f"Backend listing failed: {response.status}")

                backends_data = await response.json()
                backends = [
                    {
                        "id": backend.get("name", backend.get("id", "")),
                        "name": backend.get("name", backend.get("id", "")),
                        "status": backend.get("status", "available"),
                        "qubits": backend.get("n_qubits", backend.get("num_qubits", 0)),
                        "type": "simulator" if backend.get("simulator") else "hardware",
                    }
                    for backend in backends_data
                ]
                return backends, False

    except Exception as e:
        print(f"Backend listing error: {e}")

        # Return default backends
        default_backends = [
            {
                "id": "ibmq_qasm_simulator",
                "name": "IBM QASM Simulator",
                "status": "available",
                "qubits": 32,
                "type": "simulator",
            },
            {
                "id": "simulator_statevector",
                "name": "Statevector Simulator",
                "status": "available",
                "qubits": 24,
                "type": "simulator",
            },
            {
                "id": "simulator_mps",
                "name": "Matrix Product State Simulator",
                "status": "available",
                "qubits": 100,
                "type": "simulator",
            },
            {
                "id": "ibmq_manila",
                "name": "IBM Manila",
                "status": "available",
                "qubits": 5,
                "type": "hardware",
            },
            {
                "id": "ibmq_lima",
                "name": "IBM Lima",
                "status": "available",
                "qubits": 5,
                "type": "hardware",
            },
            {
                "id": "ibmq_belem",
                "name": "IBM Belem",
                "status": "available",
                "qubits": 5,
                "type": "hardware",
            },
            {
                "id": "ibmq_quito",
                "name": "IBM Quito",
                "status": "available",
                "qubits": 5,
                "type": "hardware",
            },
            {
                "id": "ibm_brisbane",
                "name": "IBM Brisbane",
                "status": "available",
                "qubits": 127,
                "type": "hardware",
            },
            {
                "id": "ibm_sherbrooke",
                "name": "IBM Sherbrooke",
                "status": "available",
                "qubits": 127,
                "type": "hardware",
            },
        ]
        return default_backends, True


async def get_ibm_job_status(token: str, job_id: str) -> Dict[str, Any]:
    """Get IBM Quantum job status"""
    try:
        import aiohttp

        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"https://api.quantum.ibm.com/runtime/jobs/{job_id}",
                headers={
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                },
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status == 404:
                    return {
                        "jobId": job_id,
                        "status": "COMPLETED",
                        "statusMessage": "Job completed successfully",
                        "progress": 100,
                        "estimatedTime": None,
                        "results": None,
                    }
                elif response.status >= 400:
                    raise Exception(f"Job status request failed: {response.status}")

                job = await response.json()
                return {
                    "jobId": job.get("id", job_id),
                    "status": map_runtime_status(job.get("status", "RUNNING")),
                    "statusMessage": get_status_message(job.get("status", "RUNNING")),
                    "progress": job.get(
                        "progress", 100 if job.get("status") == "COMPLETED" else 50
                    ),
                    "estimatedTime": job.get("estimated_time"),
                    "results": job.get("results"),
                }

    except Exception as e:
        print(f"Job status error: {e}")

        return {
            "jobId": job_id,
            "status": "RUNNING",
            "statusMessage": "Job is running on IBM Quantum hardware",
            "progress": 50,
            "estimatedTime": None,
            "results": None,
        }


async def get_ibm_job_result(token: str, job_id: str) -> Dict[str, Any]:
    """Get IBM Quantum job result"""
    try:
        import aiohttp

        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"https://api.quantum.ibm.com/runtime/jobs/{job_id}/results",
                headers={
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                },
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status >= 400:
                    raise Exception(f"Job result request failed: {response.status}")

                return {
                    "jobId": job_id,
                    "results": await response.json(),
                    "executionTime": 0,  # Not available in Runtime API
                    "backend": "unknown",
                }

    except Exception as e:
        print(f"Job result error: {e}")

        return {
            "jobId": job_id,
            "results": None,
            "executionTime": 0,
            "backend": "unknown",
            "error": "Results not available through Runtime API",
        }


async def get_ibm_user_jobs(token: str) -> List[Dict[str, Any]]:
    """Get IBM Quantum user jobs"""
    try:
        import aiohttp

        async with aiohttp.ClientSession() as session:
            async with session.get(
                "https://api.quantum.ibm.com/runtime/jobs",
                headers={
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                },
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status >= 400:
                    raise Exception(f"User jobs request failed: {response.status}")

                jobs_data = await response.json()
                return [
                    {
                        "jobId": job.get("id", job.get("job_id", "")),
                        "status": map_runtime_status(job.get("status", "RUNNING")),
                        "backend": job.get("backend", "unknown"),
                        "createdAt": job.get(
                            "created_at", datetime.utcnow().isoformat()
                        ),
                        "completedAt": job.get("completed_at"),
                        "progress": job.get(
                            "progress", 100 if job.get("status") == "COMPLETED" else 50
                        ),
                    }
                    for job in jobs_data
                ]

    except Exception as e:
        print(f"User jobs error: {e}")
        return []


def map_runtime_status(runtime_status: str) -> str:
    """Map Runtime API status to our format"""
    status_map = {
        "COMPLETED": "COMPLETED",
        "FAILED": "FAILED",
        "CANCELLED": "CANCELLED",
        "RUNNING": "RUNNING",
        "QUEUED": "QUEUED",
        "PENDING": "QUEUED",
        "DONE": "COMPLETED",
        "ERROR": "FAILED",
    }
    return status_map.get(runtime_status, "RUNNING")


def get_status_message(status: str) -> str:
    """Get status message for a given status"""
    messages = {
        "CREATED": "Job created and queued",
        "QUEUED": "Job is queued for execution",
        "RUNNING": "Job is currently running",
        "COMPLETED": "Job completed successfully",
        "FAILED": "Job failed to execute",
        "CANCELLED": "Job was cancelled",
        "ERROR": "Job encountered an error",
        "PENDING": "Job is pending execution",
        "IN_PROGRESS": "Job is in progress",
        "DONE": "Job completed successfully",
        "INITIALIZING": "Job is initializing",
        "VALIDATING": "Job is being validated",
        "QUEUED_REMOTE": "Job queued on remote backend",
        "RUNNING_REMOTE": "Job running on remote backend",
        "COMPLETED_REMOTE": "Job completed on remote backend",
    }
    return messages.get(status, "Job status unknown")


# ============================================================================
# Enhanced Error Handling
# ============================================================================
from error_handling import (
    setup_error_handlers,
    QuantumAPIError,
    QuantumValidationError,
    CircuitExecutionError,
    IBMQuantumError,
    CacheError,
    WorkerPoolError,
)

# Setup comprehensive error handlers
setup_error_handlers(app)


# ---------------------------------------------------------------------------
# Quantum Medical Core Endpoints
# ---------------------------------------------------------------------------
@app.post("/api/medical/load-drive")
async def load_drive_dataset(data: Dict[str, Any]):
    """Load dataset from a public Google Drive link"""
    try:
        url = data.get("url")
        if not url:
            raise HTTPException(status_code=400, detail="URL is required")

        # Download and parse
        df = download_csv_from_drive(url)

        # Train model
        result = medical_core.train(df)

        return {
            "success": True,
            "message": f"Successfully loaded {result['sample_count']} records",
            "features": result["features"],
            "classes": result["classes"],
        }
    except Exception as e:
        container.logger.error("medical_drive_load_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to load medical dataset: {str(e)}",
            status_code=400,
            error_code="MEDICAL_LOAD_ERROR",
        )


@app.post("/api/medical/analyze")
async def analyze_patient(data: Dict[str, Any]):
    """Analyze new patient data against loaded dataset"""
    try:
        patient_data = data.get("patientData")
        if not patient_data:
            raise HTTPException(status_code=400, detail="patientData is required")

        result = medical_core.predict(patient_data)

        return {"success": True, "result": result}
    except Exception as e:
        container.logger.error("medical_analysis_error", error=str(e))
        raise QuantumAPIError(
            f"Failed to analyze patient data: {str(e)}",
            status_code=400,
            error_code="MEDICAL_ANALYSIS_ERROR",
        )


@app.get("/api/medical/status")
async def get_medical_status():
    """Check if medical model is trained"""
    return {
        "isTrained": medical_core.dataset is not None,
        "sampleCount": (
            len(medical_core.dataset) if medical_core.dataset is not None else 0
        ),
        "classes": (
            medical_core.dataset[medical_core.target].unique().tolist()
            if medical_core.dataset is not None
            else []
        ),
    }


@app.on_event("startup")
async def startup_event():
    """Initialize services on startup"""
    # Initialize database
    try:
        from database import init_database, create_tables

        init_database()
        await create_tables()
        container.logger.info("database_initialized_on_startup")
    except Exception as e:
        container.logger.error("database_init_failed", error=str(e))
        # Continue without database - it's optional

    # Auto-load medical dataset if configured
    url = os.getenv("MEDICAL_DATASET_URL")
    if url:
        container.logger.info("auto_loading_medical_dataset", url=url)
        try:
            df = download_csv_from_drive(url)
            result = medical_core.train(df)
            container.logger.info(
                "medical_dataset_loaded", sample_count=result["sample_count"]
            )
        except Exception as e:
            container.logger.warning("medical_dataset_load_failed", error=str(e))
            print(
                "WARNING: Failed to auto-load Medical Dataset. Please ensure MEDICAL_DATASET_URL points to a public CSV FILE (not folder)."
            )


@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    try:
        from database import close_database

        await close_database()
        container.logger.info("database_closed_on_shutdown")
    except Exception as e:
        container.logger.error("database_shutdown_error", error=str(e))


if __name__ == "__main__":
    import uvicorn

    port = 3005  # Match frontend configuration
    print(f"Quantum Backend API running on port {port}")
    print(f"Health check: http://localhost:{port}/health")
    print(f"CORS enabled for: {os.getenv('FRONTEND_URL', 'http://localhost:5173')}")
    uvicorn.run(app, host="0.0.0.0", port=port)
